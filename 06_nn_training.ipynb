{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd0961c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 22:57:13.127265: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-13 22:57:13.428923: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-13 22:57:13.428944: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-13 22:57:13.470390: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-13 22:57:14.301212: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-13 22:57:14.301333: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-13 22:57:14.301340: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3aee00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dades/points_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a89b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select quantitatives variables\n",
    "quant_var = df[[\"altitut\", \"pendent\", \"orientacio\", \"t_max\", \"u\", \"v\", \"specific_humidity\", \"relative_humidity\"]]\n",
    "# Normalize\n",
    "mean = quant_var.mean()\n",
    "mean.to_csv(\"dades/means.csv\")\n",
    "std = quant_var.std()\n",
    "std.to_csv(\"dades/stds.csv\")\n",
    "normalized_df = (quant_var-quant_var.mean())/quant_var.std()\n",
    "# Add soil use binarizaded\n",
    "normalized_df = normalized_df.join(pd.get_dummies(df[\"coberta_sol\"].astype(\"category\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e521aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "y = df[\"fire\"]\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(normalized_df, y, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d6be5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 22:57:15.360056: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-13 22:57:15.360188: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-13 22:57:15.360204: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (xpasku-PROX15-AMD): /proc/driver/nvidia/version does not exist\n",
      "2022-12-13 22:57:15.360423: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Design neural net\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv1D(64, kernel_size=1, activation='relu', input_shape=(19,1)))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    \n",
    "model.add(keras.layers.Conv1D(128, 3, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "   \n",
    "model.add(keras.layers.Conv1D(256, 3, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f4bc794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "197/197 [==============================] - 2s 5ms/step - loss: 0.2624 - accuracy: 0.8963\n",
      "Epoch 2/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.2186 - accuracy: 0.9156\n",
      "Epoch 3/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.2128 - accuracy: 0.9183\n",
      "Epoch 4/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.1985 - accuracy: 0.9212\n",
      "Epoch 5/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.1977 - accuracy: 0.9210\n",
      "Epoch 6/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.1904 - accuracy: 0.9247\n",
      "Epoch 7/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.1847 - accuracy: 0.9254\n",
      "Epoch 8/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.1823 - accuracy: 0.9250\n",
      "Epoch 9/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.1782 - accuracy: 0.9286\n",
      "Epoch 10/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.1737 - accuracy: 0.9308\n",
      "Epoch 11/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.1638 - accuracy: 0.9339\n",
      "Epoch 12/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.1632 - accuracy: 0.9358\n",
      "Epoch 13/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.1499 - accuracy: 0.9405\n",
      "Epoch 14/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.1552 - accuracy: 0.9391\n",
      "Epoch 15/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.1467 - accuracy: 0.9380\n",
      "Epoch 16/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.1436 - accuracy: 0.9405\n",
      "Epoch 17/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.1438 - accuracy: 0.9421\n",
      "Epoch 18/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.1399 - accuracy: 0.9411\n",
      "Epoch 19/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.1337 - accuracy: 0.9484\n",
      "Epoch 20/20\n",
      "197/197 [==============================] - 1s 5ms/step - loss: 0.1305 - accuracy: 0.9440\n",
      "50/50 [==============================] - 0s 2ms/step\n",
      "Confusion matrix: [[748  48]\n",
      " [ 73 708]]\n",
      "\n",
      "P-Score: 0.937, R-Score: 0.907\n"
     ]
    }
   ],
   "source": [
    "# Define the accuracy metrics and parameters\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Run the model\n",
    "model.fit(xTrain, yTrain, epochs=20)\n",
    "\n",
    "# Predict for test data \n",
    "yTestPredicted = model.predict(xTest)\n",
    "yTestPredicted = yTestPredicted[:,1]\n",
    "\n",
    "# Calculate the error metrics\n",
    "yTestPredicted = (yTestPredicted>0.5).astype(int)\n",
    "cMatrix = confusion_matrix(yTest, yTestPredicted)\n",
    "pScore = precision_score(yTest, yTestPredicted)\n",
    "rScore = recall_score(yTest, yTestPredicted)\n",
    "\n",
    "print(\"Confusion matrix:\", cMatrix)\n",
    "print(\"\\nP-Score: %.3f, R-Score: %.3f\" % (pScore, rScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af0c761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model\n",
    "model.save(\"dades/nn_fire_risk.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
